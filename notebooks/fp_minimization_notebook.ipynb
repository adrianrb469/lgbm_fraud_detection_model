{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b2ea850",
   "metadata": {},
   "source": [
    "# Fraud‑Detection: Minimizing False Positives for Legitimate Frequent Customers\n",
    "\n",
    "A complete, reproducible pipeline using **LightGBM** and custom metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4348d6ec",
   "metadata": {},
   "source": [
    "**Goal**: keep ⬆️ fraud recall (~90%) while driving ⬇️ false‑positive rate, giving *extra weight* to legitimate transactions from frequent customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c9110e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dec9a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1852394, 55)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../data/processed/'      # <-- adjust if needed\n",
    "df = pd.read_csv(os.path.join(DATA_PATH, 'transactions_processed.csv'))\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c904df01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1570873, 55) (141983, 55) (139538, 55)\n"
     ]
    }
   ],
   "source": [
    "# December 2020 as blind test, October‑November 2020 as validation, rest train\n",
    "test_mask  = (df['year']==2020) & (df['trans_month']==12)\n",
    "valid_mask = (df['year']==2020) & (df['trans_month'].between(10,11))\n",
    "train_mask = ~test_mask & ~valid_mask\n",
    "\n",
    "train_df, valid_df, test_df = df[train_mask], df[valid_mask], df[test_mask]\n",
    "print(train_df.shape, valid_df.shape, test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50302274",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'is_fraud'\n",
    "ignore = [target,'transaction_datetime']\n",
    "\n",
    "features = [c for c in df.columns if c not in ignore]\n",
    "cat_cols = [c for c in features if df[c].dtype=='object']\n",
    "\n",
    "for c in cat_cols:\n",
    "    for part in (train_df, valid_df, test_df):\n",
    "        part[c] = part[c].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "082e4df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heavier weight for *legitimate* frequent customers\n",
    "def make_weights(part):\n",
    "    w = np.ones(len(part))\n",
    "    frequent = (part['is_frequent_merchant'] == 1) & (part[target]==0)\n",
    "    w[frequent] = 5.0\n",
    "    return w\n",
    "\n",
    "w_train = make_weights(train_df)\n",
    "w_valid = make_weights(valid_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa69066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- build Datasets exactly as before (no set_field) ----\n",
    "lgb_train = lgb.Dataset(train_df[features], label=train_df[target],\n",
    "                        weight=w_train, categorical_feature=cat_cols,\n",
    "                        free_raw_data=False)\n",
    "lgb_valid = lgb.Dataset(valid_df[features], label=valid_df[target],\n",
    "                        weight=w_valid, categorical_feature=cat_cols,\n",
    "                        free_raw_data=False, reference=lgb_train)\n",
    "\n",
    "# ---- map Dataset‐id → frequent‑flag array ----\n",
    "freq_map = {\n",
    "    id(lgb_train): train_df['is_frequent_merchant'].values,\n",
    "    id(lgb_valid): valid_df['is_frequent_merchant'].values\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc6bca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp_tp_ratio(preds, data):\n",
    "    \"\"\"FP/TP ratio among frequent customers (lower is better).\"\"\"\n",
    "    y_true     = data.get_label()\n",
    "    freq_flag  = freq_map[id(data)]\n",
    "    y_pred     = preds > 0.5\n",
    "\n",
    "    tp        = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp_freq   = np.sum((y_true == 0) & (y_pred == 1) & (freq_flag == 1))\n",
    "    ratio     = (tp + fp_freq) / tp if tp else np.inf\n",
    "    return 'fp_tp_ratio', ratio, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f000d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d016cc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's auc: 0.961389\ttrain's fp_tp_ratio: 2.86492\tvalid's auc: 0.88001\tvalid's fp_tp_ratio: 4.53012\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttrain's auc: 0.972668\ttrain's fp_tp_ratio: 2.70685\tvalid's auc: 0.963075\tvalid's fp_tp_ratio: 2.8559\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import early_stopping, log_evaluation\n",
    "\n",
    "\n",
    "\n",
    "params = dict(objective='binary', metric='auc',\n",
    "              learning_rate=0.05, num_leaves=64,\n",
    "              feature_fraction=0.8, bagging_fraction=0.8,\n",
    "              bagging_freq=5, seed=42, verbosity=-1)\n",
    "\n",
    "\n",
    "params.update({\n",
    "    \"scale_pos_weight\": 50,   # instead of the 500‑ish auto value\n",
    "    \"min_child_weight\": 0.1,  # let leaves split on fewer frauds\n",
    "    \"metric\": \"auc\",          # let LightGBM optimise AUC; keep fp_tp in feval\n",
    "})\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    valid_sets=[lgb_train, lgb_valid],\n",
    "    valid_names=['train', 'valid'],\n",
    "    feval=fp_tp_ratio,\n",
    "    num_boost_round=500,\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=50),   # <-- replaces early_stopping_rounds\n",
    "        log_evaluation(period=50)             # nice progress print‑outs\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23d574bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected threshold: 0.004\n"
     ]
    }
   ],
   "source": [
    "valid_pred = model.predict(valid_df[features])\n",
    "precision, recall, thresh = precision_recall_curve(valid_df[target], valid_pred)\n",
    "# pick highest threshold with recall >= 0.90\n",
    "thr = thresh[np.where(recall[:-1] >= 0.90)[0][-1]]\n",
    "print(f'Selected threshold: {thr:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2566985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[133381   5899]\n",
      " [    37    221]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9576    0.9782    139280\n",
      "           1     0.0361    0.8566    0.0693       258\n",
      "\n",
      "    accuracy                         0.9575    139538\n",
      "   macro avg     0.5179    0.9071    0.5238    139538\n",
      "weighted avg     0.9979    0.9575    0.9766    139538\n",
      "\n",
      "Overall FP/TP ratio: 27.692\n",
      "Frequent‑cust FP/TP ratio: 27.692\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(test_df[features])\n",
    "y_true = test_df[target].values\n",
    "y_hat  = (test_pred >= thr).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_hat)\n",
    "print('Confusion matrix\\n', cm)\n",
    "\n",
    "report = classification_report(y_true, y_hat, digits=4)\n",
    "print(report)\n",
    "\n",
    "# FPR overall and for frequent customers\n",
    "fp  = cm[0,1]; tp = cm[1,1]\n",
    "freq_mask = (test_df['is_frequent_merchant']==1) & (y_true==0)\n",
    "fp_freq = ((y_hat==1) & freq_mask).sum()\n",
    "ratio_overall = (tp+fp)/tp\n",
    "ratio_freq    = (tp+fp_freq)/tp\n",
    "print(f'Overall FP/TP ratio: {ratio_overall:.3f}')\n",
    "print(f'Frequent‑cust FP/TP ratio: {ratio_freq:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19f0e266",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
