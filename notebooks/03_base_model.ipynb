{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b2ea850",
   "metadata": {},
   "source": [
    "# 03 - Base Model and Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c9110e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dec9a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/processed/'     \n",
    "\n",
    "df = pd.read_csv(os.path.join(DATA_PATH, 'transactions_processed.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c904df01",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mask  = (df['year']==2020) & (df['trans_month']==12)\n",
    "valid_mask = (df['year']==2020) & (df['trans_month'].between(10,11))\n",
    "train_mask = ~test_mask & ~valid_mask\n",
    "\n",
    "train_df, valid_df, test_df = df[train_mask], df[valid_mask], df[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50302274",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'is_fraud'\n",
    "ignore = [target,'transaction_datetime']\n",
    "\n",
    "features = [c for c in df.columns if c not in ignore]\n",
    "cat_cols = [c for c in features if df[c].dtype=='object']\n",
    "\n",
    "#  LightGBM requires categorical features instead of object dtype.\n",
    "for c in cat_cols:\n",
    "    for part in (train_df, valid_df, test_df):\n",
    "        part[c] = part[c].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "082e4df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weights(part, legit_freq_w=10.0):\n",
    "    \"\"\"Boost loss on legitimate frequent‑customer rows.\"\"\"\n",
    "    w = np.ones(len(part))\n",
    "    mask = (part['is_frequent_merchant'] == 1) & (part[target] == 0)\n",
    "    w[mask] = legit_freq_w         \n",
    "    return w\n",
    "\n",
    "w_train = make_weights(train_df, legit_freq_w=5.0)\n",
    "w_valid = make_weights(valid_df, legit_freq_w=5.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa69066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(train_df[features], label=train_df[target],\n",
    "                        weight=w_train, categorical_feature=cat_cols,\n",
    "                        free_raw_data=False)\n",
    "lgb_valid = lgb.Dataset(valid_df[features], label=valid_df[target],\n",
    "                        weight=w_valid, categorical_feature=cat_cols,\n",
    "                        free_raw_data=False, reference=lgb_train)\n",
    "\n",
    "freq_map = {\n",
    "    id(lgb_train): train_df['is_frequent_merchant'].values,\n",
    "    id(lgb_valid): valid_df['is_frequent_merchant'].values\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b90699",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50f3d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpi_report(model, df, name, thr):\n",
    "    \"\"\"\n",
    "        Helper function to print KPIs\n",
    "        @param model: trained LightGBM model\n",
    "        @param df: dataframe to evaluate\n",
    "        @param name: name of the dataframe\n",
    "        @param thr: threshold for the model\n",
    "\n",
    "        Prints:\n",
    "        - Recall (fraud detection rate)\n",
    "        - Overall FPR (false positive rate for overall transactions)\n",
    "        - Frequent‑cust FPR (false positive rate for frequent customers)\n",
    "        - Overall FP/TP ratio (overall fraud detection rate)\n",
    "        - Freq‑cust FP/TP ratio (fraud detection rate for frequent customers)\n",
    "    \"\"\"\n",
    "    predictions = model.predict(df[features])\n",
    "    actuals = df[target].values\n",
    "    is_frequent = df[\"is_frequent_merchant\"].values\n",
    "    predicted_fraud = predictions >= thr\n",
    "\n",
    "    tp = ((actuals == 1) & predicted_fraud).sum()\n",
    "    fn = ((actuals == 1) & ~predicted_fraud).sum()\n",
    "    fp = ((actuals == 0) & predicted_fraud).sum()\n",
    "\n",
    "    fp_freq = ((actuals == 0) & predicted_fraud & (is_frequent == 1)).sum()\n",
    "    legitimate_freq = ((actuals == 0) & (is_frequent == 1)).sum()\n",
    "\n",
    "    recall = tp / (tp + fn)\n",
    "    fpr = fp / (actuals == 0).sum()\n",
    "    fpr_freq = fp_freq / legitimate_freq\n",
    "\n",
    "    fp_tp_ratio_overall = (tp + fp) / tp\n",
    "    fp_tp_ratio_freq = (tp + fp_freq) / tp\n",
    "\n",
    "    print(f\"\\n{name} set @ thr={thr:.3f}\")\n",
    "    print(f\"Recall (fraud)............. {recall:.3%}\")\n",
    "    print(f\"Overall FPR................. {fpr:.3%}\")\n",
    "    print(f\"Frequent‑cust FPR.......... {fpr_freq:.3%}\")\n",
    "    print(f\"Overall FP/TP ratio........ {fp_tp_ratio_overall:.2f}\")\n",
    "    print(f\"Freq‑cust FP/TP ratio...... {fp_tp_ratio_freq:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a0913a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.963712\n"
     ]
    }
   ],
   "source": [
    "params = dict(objective='binary', metric='auc',\n",
    "              learning_rate=0.05, num_leaves=64,\n",
    "              feature_fraction=0.8, bagging_fraction=0.8,\n",
    "              bagging_freq=5, seed=42, verbosity=-1, scale_pos_weight=50, min_child_weight=0.1)\n",
    "\n",
    "params_base = params.copy()\n",
    "params_base['metric'] = 'auc'  \n",
    "\n",
    "model_base = lgb.train(\n",
    "    params_base,\n",
    "    lgb_train,\n",
    "    valid_sets=[lgb_valid],\n",
    "    valid_names=['valid'],\n",
    "    num_boost_round=500,\n",
    "    callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bdb54e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set @ thr=0.900\n",
      "Recall (fraud)............. 88.791%\n",
      "Overall FPR................. 0.764%\n",
      "Frequent‑cust FPR.......... 0.593%\n",
      "Overall FP/TP ratio........ 2.79\n",
      "Freq‑cust FP/TP ratio...... 1.15\n",
      "\n",
      "Test set @ thr=0.900\n",
      "Recall (fraud)............. 84.496%\n",
      "Overall FPR................. 0.839%\n",
      "Frequent‑cust FPR.......... 0.577%\n",
      "Overall FP/TP ratio........ 6.36\n",
      "Freq‑cust FP/TP ratio...... 1.49\n"
     ]
    }
   ],
   "source": [
    "kpi_report(model_base, valid_df, \"Validation\", 0.9)\n",
    "kpi_report(model_base, test_df, \"Test\", 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8933a7",
   "metadata": {},
   "source": [
    "### Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc6bca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp_tp_ratio_freq(preds, data):\n",
    "    y_true = data.get_label()\n",
    "    freq   = freq_map[id(data)]      # from your earlier `freq_map`\n",
    "    y_pred = preds > 0.50\n",
    "    tp     = ((y_true==1) &  y_pred).sum()\n",
    "    fp_f   = ((y_true==0) &  y_pred & (freq==1)).sum()\n",
    "    ratio  = (tp + fp_f) / tp if tp else np.inf\n",
    "    return 'fp_tp_ratio_freq', ratio, False\n",
    "\n",
    "def fp_tp_ratio(preds, data):\n",
    "    y_true  = data.get_label()\n",
    "    y_pred  = preds > 0.50           # fixed cut‑off inside metric\n",
    "    tp      = ((y_true==1) &  y_pred).sum()\n",
    "    fp      = ((y_true==0) &  y_pred).sum()\n",
    "    ratio   = (tp + fp) / tp if tp else np.inf   # lower = better\n",
    "    return 'fp_tp_ratio', ratio, False\n",
    "\n",
    "def balanced_cost(preds, data, w_fp=3.0, w_fn=10.0):\n",
    "    \"\"\"\n",
    "    Penalizes false positives on frequent customers,\n",
    "    and false negatives (missed frauds).\n",
    "    Higher w_fn puts more pressure on recall.\n",
    "    \"\"\"\n",
    "    y_true = data.get_label()\n",
    "    freq   = freq_map[id(data)]\n",
    "    y_pred = preds > 0.50\n",
    "\n",
    "    fp_freq = ((y_true==0) & y_pred & (freq==1)).sum()\n",
    "    fn      = ((y_true==1) & ~y_pred).sum()\n",
    "    cost    = w_fp * fp_freq + w_fn * fn\n",
    "    return 'balanced_cost', cost, False\n",
    "\n",
    "def f05_score(preds, data):\n",
    "    \"\"\"F‑beta with β=0.5: weigh precision twice recall (good for FP control).\"\"\"\n",
    "    y_true = data.get_label()\n",
    "    y_pred = preds > 0.50\n",
    "    tp = ((y_true==1) & y_pred).sum()\n",
    "    fp = ((y_true==0) & y_pred).sum()\n",
    "    fn = ((y_true==1) & ~y_pred).sum()\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0\n",
    "    recall    = tp / (tp + fn) if (tp + fn) else 0\n",
    "    beta2 = 0.25         # (0.5)^2\n",
    "    score = (1 + beta2) * precision * recall / (beta2 * precision + recall) if (precision+recall) else 0\n",
    "    return 'f05_score', -score, True          # LightGBM maximises; we send negative so “lower is better”\n",
    "\n",
    "def freq_fpr(preds, data):\n",
    "    \"\"\" \n",
    "        Frequent customer false positive rate \n",
    "        FP_freq / Legit_freq\n",
    "        \n",
    "    \"\"\"\n",
    "    y_true = data.get_label()\n",
    "    freq   = freq_map[id(data)]\n",
    "    y_pred = preds > 0.50\n",
    "    fp_freq  = ((y_true==0) & y_pred & (freq==1)).sum()\n",
    "    legit_freq = ((y_true==0) & (freq==1)).sum()\n",
    "    fpr = fp_freq / legit_freq if legit_freq else 0\n",
    "    return 'freq_fpr', fpr, False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d016cc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model: fp_tp_ratio  (w=10)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's binary_logloss: 0.00759189\tvalid's fp_tp_ratio: 1.51102\n",
      "[200]\tvalid's binary_logloss: 0.00630076\tvalid's fp_tp_ratio: 1.25887\n",
      "[300]\tvalid's binary_logloss: 0.0059466\tvalid's fp_tp_ratio: 1.16632\n",
      "Early stopping, best iteration is:\n",
      "[319]\tvalid's binary_logloss: 0.00590922\tvalid's fp_tp_ratio: 1.15546\n",
      "Best fp_tp_ratio: 1.1555\n",
      "\n",
      " Model: fp_tp_ratio_freq  (w=10)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's binary_logloss: 0.00759189\tvalid's fp_tp_ratio_freq: 1.02605\n",
      "[200]\tvalid's binary_logloss: 0.00630076\tvalid's fp_tp_ratio_freq: 1.01461\n",
      "[300]\tvalid's binary_logloss: 0.0059466\tvalid's fp_tp_ratio_freq: 1.01053\n",
      "Early stopping, best iteration is:\n",
      "[319]\tvalid's binary_logloss: 0.00590922\tvalid's fp_tp_ratio_freq: 1.0084\n",
      "Best fp_tp_ratio_freq: 1.0084\n",
      "\n",
      " Model: balanced_cost  (w=10)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid's binary_logloss: 0.0166253\tvalid's balanced_cost: 1088\n",
      "Best balanced_cost: 1088.0000\n",
      "\n",
      " Model: f05_score  (w=10)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's binary_logloss: 0.0435814\tvalid's f05_score: -0.298777\n",
      "Best f05_score: -0.2988\n",
      "\n",
      " Model: freq_fpr  (w=10)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's binary_logloss: 0.00759189\tvalid's freq_fpr: 0.000876542\n",
      "[200]\tvalid's binary_logloss: 0.00630076\tvalid's freq_fpr: 0.000471984\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid's binary_logloss: 0.00663957\tvalid's freq_fpr: 0.000471984\n",
      "Best freq_fpr: 0.0005\n"
     ]
    }
   ],
   "source": [
    "metrics = [fp_tp_ratio, fp_tp_ratio_freq, balanced_cost, f05_score, freq_fpr]\n",
    "\n",
    "\n",
    "def run_and_log(feval_fn, legit_freq_w=10.0):\n",
    "    w_train = make_weights(train_df, legit_freq_w)\n",
    "    w_valid = make_weights(valid_df, legit_freq_w)\n",
    "    lgb_train.set_weight(w_train)\n",
    "    lgb_valid.set_weight(w_valid)\n",
    "\n",
    "    print(f\"\\n Model: {feval_fn.__name__}  (w={legit_freq_w})\")\n",
    "\n",
    "    params = dict(\n",
    "        objective=\"binary\",\n",
    "        # metric=\"auc\"\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=64,\n",
    "        feature_fraction=0.8,\n",
    "        bagging_fraction=0.8,\n",
    "        bagging_freq=5,\n",
    "        seed=42,\n",
    "        verbosity=-1,\n",
    "        scale_pos_weight=50,\n",
    "        min_child_weight=0.1,\n",
    "    )\n",
    "\n",
    "    mdl = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        valid_sets=[lgb_valid],\n",
    "        valid_names=[\"valid\"],\n",
    "        feval=feval_fn,\n",
    "        num_boost_round=500,\n",
    "        callbacks=[early_stopping(50), log_evaluation(100)],\n",
    "    )\n",
    "\n",
    "    best = mdl.best_score[\"valid\"][feval_fn.__name__]\n",
    "    print(f\"Best {feval_fn.__name__}: {best:.4f}\")\n",
    "    return mdl, best\n",
    "\n",
    "\n",
    "results = {}\n",
    "models = {}\n",
    "for fe in metrics:\n",
    "    model, score = run_and_log(fe, legit_freq_w=10)  \n",
    "    results[fe.__name__] = score\n",
    "    models[fe.__name__] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "23d574bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Validation leaderboard (lower = better) ===\n",
      "f05_score            -0.2988\n",
      "freq_fpr             0.0005\n",
      "fp_tp_ratio_freq     1.0084\n",
      "fp_tp_ratio          1.1555\n",
      "balanced_cost        1088.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Validation leaderboard (lower = better) ===\")\n",
    "for k,v in sorted(results.items(), key=lambda x: x[1]):\n",
    "    print(f\"{k:20s} {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "19f0e266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model: fp_tp_ratio ===\n",
      "Threshold: 0.90\n",
      "\n",
      "Validation set @ thr=0.900\n",
      "Recall (fraud)............. 60.619%\n",
      "Overall FPR................. 0.016%\n",
      "Frequent‑cust FPR.......... 0.007%\n",
      "Overall FP/TP ratio........ 1.06\n",
      "Freq‑cust FP/TP ratio...... 1.00\n",
      "\n",
      "Test set @ thr=0.900\n",
      "Recall (fraud)............. 53.488%\n",
      "Overall FPR................. 0.022%\n",
      "Frequent‑cust FPR.......... 0.000%\n",
      "Overall FP/TP ratio........ 1.22\n",
      "Freq‑cust FP/TP ratio...... 1.00\n",
      "\n",
      "=== Model: fp_tp_ratio_freq ===\n",
      "Threshold: 0.90\n",
      "\n",
      "Validation set @ thr=0.900\n",
      "Recall (fraud)............. 60.619%\n",
      "Overall FPR................. 0.016%\n",
      "Frequent‑cust FPR.......... 0.007%\n",
      "Overall FP/TP ratio........ 1.06\n",
      "Freq‑cust FP/TP ratio...... 1.00\n",
      "\n",
      "Test set @ thr=0.900\n",
      "Recall (fraud)............. 53.488%\n",
      "Overall FPR................. 0.022%\n",
      "Frequent‑cust FPR.......... 0.000%\n",
      "Overall FP/TP ratio........ 1.22\n",
      "Freq‑cust FP/TP ratio...... 1.00\n",
      "\n",
      "=== Model: balanced_cost ===\n",
      "Threshold: 0.90\n",
      "\n",
      "Validation set @ thr=0.900\n",
      "Recall (fraud)............. 78.466%\n",
      "Overall FPR................. 0.220%\n",
      "Frequent‑cust FPR.......... 0.115%\n",
      "Overall FP/TP ratio........ 1.58\n",
      "Freq‑cust FP/TP ratio...... 1.03\n",
      "\n",
      "Test set @ thr=0.900\n",
      "Recall (fraud)............. 72.868%\n",
      "Overall FPR................. 0.282%\n",
      "Frequent‑cust FPR.......... 0.156%\n",
      "Overall FP/TP ratio........ 3.09\n",
      "Freq‑cust FP/TP ratio...... 1.15\n",
      "\n",
      "=== Model: f05_score ===\n",
      "Threshold: 0.90\n",
      "\n",
      "Validation set @ thr=0.900\n",
      "Recall (fraud)............. 85.988%\n",
      "Overall FPR................. 0.958%\n",
      "Frequent‑cust FPR.......... 0.600%\n",
      "Overall FP/TP ratio........ 3.32\n",
      "Freq‑cust FP/TP ratio...... 1.15\n",
      "\n",
      "Test set @ thr=0.900\n",
      "Recall (fraud)............. 77.519%\n",
      "Overall FPR................. 1.057%\n",
      "Frequent‑cust FPR.......... 0.496%\n",
      "Overall FP/TP ratio........ 8.36\n",
      "Freq‑cust FP/TP ratio...... 1.46\n",
      "\n",
      "=== Model: freq_fpr ===\n",
      "Threshold: 0.90\n",
      "\n",
      "Validation set @ thr=0.900\n",
      "Recall (fraud)............. 58.555%\n",
      "Overall FPR................. 0.035%\n",
      "Frequent‑cust FPR.......... 0.013%\n",
      "Overall FP/TP ratio........ 1.13\n",
      "Freq‑cust FP/TP ratio...... 1.01\n",
      "\n",
      "Test set @ thr=0.900\n",
      "Recall (fraud)............. 49.225%\n",
      "Overall FPR................. 0.047%\n",
      "Frequent‑cust FPR.......... 0.011%\n",
      "Overall FP/TP ratio........ 1.51\n",
      "Freq‑cust FP/TP ratio...... 1.02\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    print(f\"\\n=== Model: {model_name} ===\")\n",
    "    thr = 0.90\n",
    "    print(f\"Threshold: {thr:.2f}\")\n",
    "    kpi_report(model, valid_df, \"Validation\", thr)\n",
    "    kpi_report(model, test_df, \"Test\", thr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
